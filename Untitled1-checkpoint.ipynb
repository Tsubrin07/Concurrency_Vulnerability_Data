{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257c591d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plac'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7660\\588542114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcompounding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plac'"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch,compounding\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "af365ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1 = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d73fcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx1 = nlp1('A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2364e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux Kernel 20 32 PERSON\n"
     ]
    }
   ],
   "source": [
    "for token in docx1.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8723b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx2 = nlp1('A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55c7bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux Kernel 20 32 PERSON\n"
     ]
    }
   ],
   "source": [
    "for token in docx2.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3849756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    ('A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op', {\n",
    "        'entities': [(41, 110, 'Reason')]\n",
    "    }),\n",
    "     ('A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op', {\n",
    "        'entities': [(111, 153, 'Impact')]\n",
    "    }),\n",
    "    ('A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op', {\n",
    "        'entities': [(122, 138, 'Result')]\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d06a9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "output_dir=Path(\"D:\\\\ner\")\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "691ae695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6b239e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe('ner')\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0c17c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 72.42856788635254}\n",
      "{'ner': 70.88192915916443}\n",
      "{'ner': 68.66931104660034}\n",
      "{'ner': 66.39437794685364}\n",
      "{'ner': 63.46408534049988}\n",
      "{'ner': 60.10299873352051}\n",
      "{'ner': 55.19760310649872}\n",
      "{'ner': 51.20218753814697}\n",
      "{'ner': 44.61851155757904}\n",
      "{'ner': 38.100640296936035}\n",
      "{'ner': 29.67586851119995}\n",
      "{'ner': 24.383385509252548}\n",
      "{'ner': 15.935203284025192}\n",
      "{'ner': 15.460964158177376}\n",
      "{'ner': 9.375279822386801}\n",
      "{'ner': 7.810128714889288}\n",
      "{'ner': 5.986241338541731}\n",
      "{'ner': 6.311223476572195}\n",
      "{'ner': 5.8935611735869315}\n",
      "{'ner': 5.9170238815172524}\n",
      "{'ner': 5.561613753124448}\n",
      "{'ner': 5.301438610093101}\n",
      "{'ner': 5.648672549818912}\n",
      "{'ner': 5.9941876322744605}\n",
      "{'ner': 5.337644531377784}\n",
      "{'ner': 5.788472196392888}\n",
      "{'ner': 5.733537918053571}\n",
      "{'ner': 5.684150003367392}\n",
      "{'ner': 5.529688984574932}\n",
      "{'ner': 4.9861360845243325}\n",
      "{'ner': 5.725880824160413}\n",
      "{'ner': 5.740778560848412}\n",
      "{'ner': 5.51845532374864}\n",
      "{'ner': 5.07410703743335}\n",
      "{'ner': 4.892878417726024}\n",
      "{'ner': 4.71554338518763}\n",
      "{'ner': 4.888197611173382}\n",
      "{'ner': 4.4446876918082125}\n",
      "{'ner': 5.20120974908059}\n",
      "{'ner': 5.795582101702166}\n",
      "{'ner': 5.687778142168099}\n",
      "{'ner': 5.041571674908482}\n",
      "{'ner': 5.468736354932389}\n",
      "{'ner': 4.777674228815158}\n",
      "{'ner': 4.47007062937314}\n",
      "{'ner': 5.616605008332943}\n",
      "{'ner': 6.143123760453591}\n",
      "{'ner': 4.949675160453523}\n",
      "{'ner': 4.863835660231139}\n",
      "{'ner': 5.468560211983039}\n",
      "{'ner': 4.895428540881298}\n",
      "{'ner': 3.6697275157823235}\n",
      "{'ner': 5.210088564263579}\n",
      "{'ner': 5.767307919837542}\n",
      "{'ner': 5.448419292918089}\n",
      "{'ner': 5.218464846669875}\n",
      "{'ner': 5.054811461477875}\n",
      "{'ner': 3.524910864151906}\n",
      "{'ner': 5.778572780914231}\n",
      "{'ner': 5.515371160498361}\n",
      "{'ner': 5.615257271866428}\n",
      "{'ner': 4.777935249752744}\n",
      "{'ner': 4.909897080976096}\n",
      "{'ner': 5.059210739629538}\n",
      "{'ner': 5.258079490358066}\n",
      "{'ner': 14.016523087250114}\n",
      "{'ner': 6.180414875322697}\n",
      "{'ner': 12.516888755302716}\n",
      "{'ner': 7.148933624586334}\n",
      "{'ner': 9.258588193362812}\n",
      "{'ner': 5.070903753405219}\n",
      "{'ner': 5.85495558303046}\n",
      "{'ner': 5.109269759896989}\n",
      "{'ner': 4.820693472815037}\n",
      "{'ner': 5.327096187755615}\n",
      "{'ner': 4.7464346395221355}\n",
      "{'ner': 4.646671803969264}\n",
      "{'ner': 4.951648905509842}\n",
      "{'ner': 5.260155754014761}\n",
      "{'ner': 4.380641271981222}\n",
      "{'ner': 4.959620942616311}\n",
      "{'ner': 4.218674081307753}\n",
      "{'ner': 4.955142483160367}\n",
      "{'ner': 4.306609073026013}\n",
      "{'ner': 5.272171160118528}\n",
      "{'ner': 3.949778399921845}\n",
      "{'ner': 4.061908904088091}\n",
      "{'ner': 4.967626692148299}\n",
      "{'ner': 4.154900362087943}\n",
      "{'ner': 5.164330552009911}\n",
      "{'ner': 4.831294199982801}\n",
      "{'ner': 4.286157902936951}\n",
      "{'ner': 8.620186370859123}\n",
      "{'ner': 10.615025864147938}\n",
      "{'ner': 23.22791710790131}\n",
      "{'ner': 16.867432183552125}\n",
      "{'ner': 15.041085890723139}\n",
      "{'ner': 7.719758982562098}\n",
      "{'ner': 13.13662483977896}\n",
      "{'ner': 16.80653513494599}\n"
     ]
    }
   ],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            examples = []\n",
    "            for text, annotations in batch:\n",
    "                example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "                examples.append(example)\n",
    "            nlp.update(\n",
    "                examples,  \n",
    "                drop=0.5,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cddd3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('access to', 'Reason'), ('leading to a use after free in con_font_op', 'Impact')]\n",
      "Entities [('access to', 'Reason'), ('leading to a use after free in con_font_op', 'Impact')]\n",
      "Entities [('access to', 'Reason'), ('leading to a use after free in con_font_op', 'Impact')]\n"
     ]
    }
   ],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    #print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cb270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d05be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
